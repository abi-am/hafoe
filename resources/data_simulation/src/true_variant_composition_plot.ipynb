{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      \n      require([\"gridstack\"], function(GridStack) {\n\t\n\twindow.GridStack = GridStack\n\t\n\ton_load()\n      })\n      \n      root._bokeh_is_loading = css_urls.length + 1;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }\n    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/debugger.css\", \"https://unpkg.com/@holoviz/panel@0.13.0/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import bokeh as bk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from bokeh.io import output_file, save, export_svgs, export_png\n",
    "from bokeh.io import show\n",
    "from bokeh.layouts import gridplot, row, widgetbox, layout, grid\n",
    "from bokeh.models import HoverTool, Arrow, NormalHead, ColumnDataSource, LinearColorMapper, FactorRange, DataTable, \\\n",
    "    PanTool, BoxZoomTool, WheelZoomTool, SaveTool, ResetTool, Div, Legend, Panel, Tabs, LabelSet\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.core.properties import value, field\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "pn.extension()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serotypes\n",
    "serotype_names = np.array([\"No alignment\", \"AAV1\", \"AAV2\", \"AAV3\", \"AAV4\", \"AAV5\", \"AAV6\", \n",
    "                \"AAV7\", \"AAV8\", \"AAV9\", \"AAV10\", \"AAV11\", \"AAV12\", \"AAV13\", \n",
    "                \"AAVrh8\", \"AAVrh10\", \"AAVrh32\", \"Multiple alignments\", \"gap\"])\n",
    "serotype_colors = np.array([\"gray\", \"#AA4488\", \"#4477AA\", \"#AAAA44\", \n",
    "                \"#AA7744\", \"#AA4455\", \"#44AAAA\", \"#771155\", \n",
    "                \"#114477\", \"#777711\", \"#774411\", \"#771122\", \n",
    "                \"#117777\", \"#A6CEE3\", \"#B2DF8A\", \"#F1B6DA\", \n",
    "                \"#B2ABD2\", \"black\", \"white\"])\n",
    "\n",
    "sorter = np.argsort(serotype_names)\n",
    "idx_del = sorter[np.searchsorted(serotype_names, [\"gap\", \"Multiple alignments\", \"No alignment\"], sorter=sorter)]\n",
    "serotype_names_del = np.delete(serotype_names, idx_del, 0)\n",
    "serotype_colors_del = np.delete(serotype_colors, idx_del, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_composition(title, serotype_dictionary, serotype_colors, serotype_names, include_text = False, plot_width = 1500, max_num_x = 3000):\n",
    "    \n",
    "    # reverse the order fot top reps to be in the top\n",
    "    ### seqs: Serotype list\n",
    "    ### keys: Library name\n",
    "    seqs = np.array(list(serotype_dictionary.values())[::-1])\n",
    "    keys = np.array(list(serotype_dictionary.keys())[::-1])\n",
    "\n",
    "    N = len(seqs[0])\n",
    "    S = len(seqs)    \n",
    "    width = 1.\n",
    "    \n",
    "    tmp = [i for s in seqs for i in s]\n",
    "    colors = [serotype_colors[i] for i in tmp]\n",
    "    serotypes = [serotype_names[i] for i in tmp]\n",
    "    \n",
    "    x = np.arange(1, N + 1)\n",
    "    y = np.arange(0, S, 1)    \n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    gx = xx.flatten()\n",
    "    gy = yy.flatten()\n",
    "    recty = gy + .1\n",
    "    h = 1/S\n",
    "    \n",
    "    plot_height = len(seqs)*15 + 50\n",
    "    x_range = bk.models.Range1d(0, N + 1, bounds = 'auto')\n",
    "    if N > max_num_x:\n",
    "        viewlen = max_num_x\n",
    "    else:\n",
    "        viewlen = N\n",
    "    view_range = (0, viewlen) \n",
    "    \n",
    "    \n",
    "    \n",
    "    source = bk.models.ColumnDataSource(dict(x=gx, y=gy, recty=recty, colors = colors, serotypes = serotypes))\n",
    "    \n",
    "    p = bk.plotting.figure(title = title, \n",
    "               plot_width = plot_width, plot_height = plot_height, \n",
    "               x_range = view_range, y_range = keys, tools = \"xwheel_zoom, xpan, reset\", \n",
    "               min_border = 0, toolbar_location = 'below')\n",
    "    \n",
    "    if include_text == True:\n",
    "        glyph = bk.models.glyphs.Text(x=\"x\", y=\"y\", text=\"text\", \n",
    "                                   text_align='center',\n",
    "                                   text_color=\"black\",\n",
    "                                   text_font=value(\"monospace\"))\n",
    "                                   #text_font_size=fontsize)\n",
    "    elif include_text == False:\n",
    "        glyph = bk.models.glyphs.Text(x=\"x\", y=\"y\", text=\"text\", \n",
    "                                   text_align='center',\n",
    "                                   text_color=\"black\",\n",
    "                                   text_font=value(\"monospace\"))\n",
    "        \n",
    "    rects = bk.models.glyphs.Rect(x = \"x\", y = \"recty\",  \n",
    "                 width = 1., height = 1., \n",
    "                 fill_color = \"colors\", \n",
    "                 line_color = None, fill_alpha = 1.)\n",
    "    \n",
    "    p.add_glyph(source, glyph)\n",
    "    p.add_glyph(source, rects)\n",
    "  \n",
    "    p.grid.visible = False\n",
    "    p.xaxis.axis_label = 'Nucleotide position'\n",
    "    p.xaxis.major_label_text_font_style = \"bold\"\n",
    "    p.yaxis.minor_tick_line_width = 0\n",
    "    p.yaxis.major_tick_line_width = 0\n",
    "    \n",
    "    \n",
    "    tooltips = [(\"serotype\", \"@serotypes\"),(\"nucleotide position\", \"@x\"),]\n",
    "    p.add_tools(bk.models.HoverTool(tooltips=tooltips))\n",
    "\n",
    "    # layout = bk.layouts.column(p, height=600, width=1500)\n",
    "    return p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_positional_serotype_abundance(title, positional_serotype_abundance, serotype_names, serotype_colors):\n",
    "    # def update_data(attrname, old, new):\n",
    "\n",
    "    #     ### Get the current slider value\n",
    "    #     smoothing_window_size = smoothing_slider.value\n",
    "            \n",
    "    #     smoothed_serotype_abundance = np.copy(positional_serotype_abundance)\n",
    "    #     for serotype_indx in np.arange(0, len(serotype_names), 1):\n",
    "    #         abundance_tmp = smoothed_serotype_abundance[serotype_indx]\n",
    "    #         smoothed_serotype_abundance[serotype_indx] = np.convolve(abundance_tmp, \n",
    "    #                                                                 np.ones(smoothing_window_size), \n",
    "    #                                                                 'same')/smoothing_window_size\n",
    "            \n",
    "    #     ### update the data container\n",
    "    #     source.data[\"abundance\"] = list(smoothed_serotype_abundance)\n",
    "\n",
    "    ### The smoothing slider\n",
    "    smoothing_slider = bk.models.Slider(start = 1, end = 500, value = 100, step = 1, title = \"Smoothing length\")\n",
    "\n",
    "    ### Prepare the plotting data\n",
    "    # placeholder array\n",
    "    positions_base = np.arange(0, np.shape(positional_serotype_abundance)[1])\n",
    "    # the main data container\n",
    "    data_dict = {}\n",
    "    data_dict[\"positions\"] = [positions_base for _ in np.arange(0, np.shape(positional_serotype_abundance)[0])]\n",
    "    data_dict[\"abundance\"] = list(positional_serotype_abundance)\n",
    "    data_dict[\"color\"] = serotype_colors\n",
    "    data_dict[\"serotypes\"] = serotype_names\n",
    "    source = bk.plotting.ColumnDataSource(data = data_dict)\n",
    "    \n",
    "    # smooth the initially displayed data with default value\n",
    "    smoothed_serotype_abundance = np.copy(positional_serotype_abundance)\n",
    "    for serotype_indx in np.arange(0, len(serotype_names), 1):\n",
    "        abundance_tmp = smoothed_serotype_abundance[serotype_indx]\n",
    "        smoothed_serotype_abundance[serotype_indx] = np.convolve(abundance_tmp, \n",
    "                                                                np.ones(100), \n",
    "                                                                'same')/100  \n",
    "    source.data[\"abundance\"] = list(smoothed_serotype_abundance)\n",
    "\n",
    "    ### Start plotting\n",
    "    p = bk.plotting.figure(title = title, \n",
    "                            width = 750, height=400,\n",
    "                            x_axis_label = \"Nucleotide position\", \n",
    "                            y_axis_label = \"Serotype abundance\")\n",
    "\n",
    "    p.multi_line(xs = 'positions', ys = 'abundance', source = source,\n",
    "                                                    line_width = 3, \n",
    "                                                    color = 'color',\n",
    "                                                    legend = 'serotypes')\n",
    "\n",
    "\n",
    "\n",
    "    p.legend.location = \"center\"\n",
    "    #p.legend.click_policy=\"hide\" not working\n",
    "    leg = p.legend[0]\n",
    "    p.add_layout(leg,'right') \n",
    "\n",
    "    ### Add a tooltip\n",
    "    tooltips = [(\"serotype\", \"@serotypes\"),]\n",
    "    p.add_tools(bk.models.HoverTool(tooltips = tooltips))\n",
    "\n",
    "\n",
    "    update_data = bk.models.CustomJS(args = dict(source=source, external_data = data_dict), code=\"\"\"\n",
    "        var data = source.data;\n",
    "        var smoothing_window_size = cb_obj.value;\n",
    "        \n",
    "        const x_external = external_data[\"positions\"];\n",
    "        const y_external = external_data[\"abundance\"];\n",
    "        \n",
    "        var chunk; var chunk_start; var chunk_end;\n",
    "        \n",
    "        data[\"positions\"] = x_external;\n",
    "        \n",
    "        console.log(\"entering loops\")\n",
    "        \n",
    "        for (var i = 0; i < x_external.length; i++) {\n",
    "\n",
    "            for (var j = 0; j <= y_external[i].length - Math.floor(smoothing_window_size/2); j++){\n",
    "            \n",
    "                if (j - Math.floor(smoothing_window_size/2) < 0)\n",
    "                    {chunk_start = 0;}\n",
    "                else\n",
    "                    {chunk_start = j - Math.floor(smoothing_window_size/2);}\n",
    "                if (j + Math.floor(smoothing_window_size/2) > y_external[i].length)\n",
    "                    {chunk_end = y_external[i].length;}\n",
    "                else\n",
    "                    {chunk_end = j + Math.floor(smoothing_window_size/2);}\n",
    "                    \n",
    "                chunk = y_external[i].slice(chunk_start, chunk_end + 1);\n",
    "                console.log(chunk)\n",
    "                data[\"abundance\"][i][j] = chunk.reduce((total, current) => total + current)/chunk.length;\n",
    "                \n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        source.change.emit();\n",
    "        \n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "    #smoothing_slider.on_change('value', update_data)\n",
    "    smoothing_slider.js_on_change('value', update_data)\n",
    "\n",
    "\n",
    "    # show the results\n",
    "    layout = bk.layouts.column(smoothing_slider, p, width = 750)\n",
    "\n",
    "    return layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_serotype_abundance_matrix(csv_path):\n",
    "    chimeric_library_df = pd.read_csv(csv_path, header = None)\n",
    "    ### Create a dictionary with chimeric_name:[serotype ids]\n",
    "    variant_description_dictionary = {}\n",
    "    for chimeric_library_item in chimeric_library_df[0]:\n",
    "        \n",
    "        chimeric_library_item_name = chimeric_library_item.split()[0]\n",
    "        chimeric_library_item_parents = np.array(chimeric_library_item.split()[1:]).astype(\"int\")\n",
    "        \n",
    "        variant_description_dictionary[chimeric_library_item_name] = chimeric_library_item_parents\n",
    "\n",
    "    ### 2-D array of chimeric composition\n",
    "    chimeric_composition_array = np.array(list(variant_description_dictionary.values()))\n",
    "\n",
    "    ### Initialize the abundance matrix ---> rows:serotypes, columns:positional abundance \n",
    "    positional_serotype_abundance = np.zeros((len(serotype_names), np.shape(chimeric_composition_array)[1]))\n",
    "\n",
    "    ### Populate the abundance matrix\n",
    "    for serotype_indx in np.arange(0, len(serotype_names), 1):\n",
    "        positional_serotype_abundance[serotype_indx] = np.sum(chimeric_composition_array == serotype_indx, axis = 0)\n",
    "    \n",
    "    # Remove gap, no alignment, multiple alignment\n",
    "    positional_serotype_abundance_del = np.delete(positional_serotype_abundance, idx_del, 0)\n",
    "\n",
    "    return positional_serotype_abundance_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vd_dictionary(csv_path):\n",
    "    chimeric_library_df = pd.read_csv(csv_path, header = None)\n",
    "    ### Create a dictionary with chimeric_name:[serotype ids]\n",
    "    variant_description_dictionary = {}\n",
    "    for chimeric_library_item in chimeric_library_df[0]:\n",
    "        \n",
    "        chimeric_library_item_name = chimeric_library_item.split()[0]\n",
    "        chimeric_library_item_parents = np.array(chimeric_library_item.split()[1:]).astype(\"int\")\n",
    "        \n",
    "        variant_description_dictionary[chimeric_library_item_name] = chimeric_library_item_parents\n",
    "    return variant_description_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = \"../../../../../hafoe/data_v4/benchmarking/hafoe_out_1_100_10_sum/files/Chimeric_rep_predicted_labels.csv\"\n",
    "\n",
    "# pred_df_initial = pd.read_csv(csv_path)\n",
    "# pred_df = pred_df_initial.iloc[:,0:2]\n",
    "# pred_df = pd.DataFrame(pred_df.iloc[:,0] +\" \"+ pred_df.iloc[:,1])\n",
    "# ### Create a dictionary with chimeric_name:[serotype ids]\n",
    "# variant_description_dictionary_pred = {}\n",
    "# for chimeric_library_item in pred_df[0]:\n",
    "    \n",
    "#     chimeric_library_item_name = chimeric_library_item.split()[0]\n",
    "#     chimeric_library_item_parents = np.array(chimeric_library_item.split()[1:]).astype(\"int\")\n",
    "    \n",
    "#     variant_description_dictionary_pred[chimeric_library_item_name] = chimeric_library_item_parents\n",
    "\n",
    "# #add 18s (gap) at the end to make variant lists of same length\n",
    "# max_len = max([len(x) for x in variant_description_dictionary_pred.values()])\n",
    "# for k,v in zip(variant_description_dictionary_pred.keys(), variant_description_dictionary_pred.values()):\n",
    "#     variant_description_dictionary_pred[k] = np.concatenate((v,np.repeat([18], max_len-len(v))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_csv_path = \"../../../../../hafoe/data_v4/benchmarking/hafoe_out_1_100_10_sum/files/variant_description/chimeric_lib_representatives/chimeric_lib_representatives_variant_description_top20_msa.csv\"\n",
    "variant_description_dictionary_pred = get_vd_dictionary(pred_csv_path)\n",
    "positional_serotype_abundance_pred = get_positional_serotype_abundance_matrix(pred_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "p1_pred = view_composition(\"Predicted compositions of synthetic chimeric library representatives\", \n",
    "                 variant_description_dictionary_pred, \n",
    "                 serotype_colors, \n",
    "                 serotype_names,\n",
    "                 plot_width=740)\n",
    "p2_pred = view_positional_serotype_abundance(\"Predicted positional serotype abundance of synthetic chimeric library representatives\",\n",
    "                                            positional_serotype_abundance_pred, \n",
    "                                            serotype_names_del, \n",
    "                                            serotype_colors_del)\n",
    "# pn.pane.Bokeh(p2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_pred = view_composition(\"Predicted compositions of synthetic chimeric library representatives\", \n",
    "#                  variant_description_dictionary_pred, \n",
    "#                  serotype_colors, \n",
    "#                  serotype_names)\n",
    "# pn.pane.Bokeh(p_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = \"../../../../../hafoe/data_v4/input_files/data1/Chimeric_lib_simulated_labels.csv\"\n",
    "# query_seq = list(variant_description_dictionary_pred.keys())\n",
    "# query_seq = [x.split(\"_\", 1)[0] for x in query_seq]\n",
    "\n",
    "# true_df = pd.read_csv(csv_path).iloc[:,0:2]\n",
    "# true_df = true_df[true_df['X'].isin(query_seq)]\n",
    "# true_df = pd.DataFrame(true_df.iloc[:,0] +\" \"+ true_df.iloc[:,1])\n",
    "\n",
    "# ### Create a dictionary with chimeric_name:[serotype ids]\n",
    "# variant_description_dictionary_true = {}\n",
    "# for chimeric_library_item in true_df[0]:\n",
    "    \n",
    "#     chimeric_library_item_name = chimeric_library_item.split()[0]\n",
    "#     chimeric_library_item_parents = np.array(chimeric_library_item.split()[1:]).astype(\"int\")\n",
    "    \n",
    "#     variant_description_dictionary_true[chimeric_library_item_name] = chimeric_library_item_parents\n",
    "\n",
    "# max_len = max([len(x) for x in variant_description_dictionary_pred.values()])\n",
    "# #add 18s (gap) at the end to make variant lists of same length\n",
    "# for k,v in zip(variant_description_dictionary_true.keys(), variant_description_dictionary_true.values()):\n",
    "#     s = pred_df_initial[pred_df_initial.X.str.match(k+'.*')]['Start_orf']-1\n",
    "#     e = pred_df_initial[pred_df_initial.X.str.match(k+'.*')]['End_orf']\n",
    "#     variant_description_dictionary_true[k] = v[int(s):int(e)]\n",
    "#     variant_description_dictionary_true[k] = np.concatenate((variant_description_dictionary_true[k],np.repeat([18], max_len-len(variant_description_dictionary_true[k]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_csv_path = \"../../../../../hafoe/data_v4/input_files/data1/Chimeric_lib_simulated_labels_top20_msa.csv\"\n",
    "variant_description_dictionary_true = get_vd_dictionary(true_csv_path)\n",
    "positional_serotype_abundance_true = get_positional_serotype_abundance_matrix(true_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "p1_true = view_composition(\"True compositions of synthetic chimeric library representatives\", \n",
    "                 variant_description_dictionary_true, \n",
    "                 serotype_colors, \n",
    "                 serotype_names,\n",
    "                 plot_width=740)\n",
    "p2_true = view_positional_serotype_abundance(\"True positional serotype abundance of synthetic chimeric library representatives\",\n",
    "                                            positional_serotype_abundance_true, \n",
    "                                            serotype_names_del, \n",
    "                                            serotype_colors_del)\n",
    "# pn.pane.Bokeh(p2_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save in a html report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokeh_composite(title, figure_layout, filename):\n",
    "\n",
    "    output_file(title + \".html\", title=title)\n",
    "\n",
    "    p = layout(figure_layout, sizing_mode=\"scale_width\")\n",
    "\n",
    "    save([p], filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_composite(\"variant_composition_accuracy\",  \n",
    "                figure_layout = [bk.layouts.column(bk.layouts.row(p2_true, p2_pred, width=1500), bk.layouts.row(p1_true, p1_pred, width=1500))], \n",
    "                filename = os.path.join(\"variant_composition_accuracy.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
